{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Attention weights, and context vectors following the Transformer attention mechanism** **bold text**"
      ],
      "metadata": {
        "id": "iIMNE1O_qwSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 1: Define Input and Projection Matrices**"
      ],
      "metadata": {
        "id": "etSIf31NsOE_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "syzLz7um0bqr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Input\n",
        "x = tf.constant([\n",
        "    [0.1, 0.2, 0.3, 0.4],\n",
        "    [0.5, 0.6, 0.7, 0.8],\n",
        "    [0.9, 1.0, 1.1, 1.2]\n",
        "], dtype=tf.float32)\n",
        "\n",
        "# Projection matrices (EXACT from manual)\n",
        "W_Q = tf.constant([\n",
        "    [0.1, 0.2, 0.3],\n",
        "    [0.4, 0.5, 0.6],\n",
        "    [0.7, 0.8, 0.9],\n",
        "    [1.0, 1.1, 0]\n",
        "], dtype=tf.float32)\n",
        "W_K = W_Q  # Same as Q\n",
        "W_V = tf.constant([\n",
        "    [0.1, 0.2],\n",
        "    [0.3, 0.4],\n",
        "    [0.5, 0.6],\n",
        "    [0.7, 0.8],\n",
        "\n",
        "], dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 2: Compute Queries, Keys, Values and Attention Scores**"
      ],
      "metadata": {
        "id": "5hZrvbNasi4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = tf.matmul(x, W_Q)\n",
        "print(\"Queries Matrix: \", queries)\n",
        "\n",
        "keys = tf.matmul(x, W_K)\n",
        "print(\"Keys Matrix:\", keys)\n",
        "\n",
        "values = tf.matmul(x, W_V)\n",
        "print(\"Values Matrix:\", values)\n",
        "\n",
        "# Compute raw attention scores (dot product of queries and keys)\n",
        "scores = tf.matmul(queries, keys, transpose_b=True)\n",
        "print(\"Attention Scores Matrix: \", scores)\n",
        "\n",
        "# Scale attention scores\n",
        "scaled = scores / tf.sqrt(3.0)  # sqrt of key dimension (3)\n",
        "print(\"Attention Score Matrix Scaled: \", scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SjiBDUAsiTn",
        "outputId": "b58bef88-457f-43ee-bc78-0ee111236f50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries Matrix:  tf.Tensor(\n",
            "[[0.70000005 0.8000001  0.42000002]\n",
            " [1.5799999  1.8400002  1.14      ]\n",
            " [2.46       2.88       1.86      ]], shape=(3, 3), dtype=float32)\n",
            "Keys Matrix: tf.Tensor(\n",
            "[[0.70000005 0.8000001  0.42000002]\n",
            " [1.5799999  1.8400002  1.14      ]\n",
            " [2.46       2.88       1.86      ]], shape=(3, 3), dtype=float32)\n",
            "Values Matrix: tf.Tensor(\n",
            "[[0.5       0.6      ]\n",
            " [1.14      1.4000001]\n",
            " [1.7800001 2.2      ]], shape=(3, 2), dtype=float32)\n",
            "Attention Scores Matrix:  tf.Tensor(\n",
            "[[ 1.3064002  3.0568004  4.8072004]\n",
            " [ 3.0568004  7.1816    11.3064   ]\n",
            " [ 4.8072004 11.3064    17.805601 ]], shape=(3, 3), dtype=float32)\n",
            "Attention Score Matrix Scaled:  tf.Tensor(\n",
            "[[ 0.7542505  1.7648445  2.7754385]\n",
            " [ 1.7648445  4.146299   6.5277534]\n",
            " [ 2.7754385  6.5277534 10.280068 ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 3: Calculate Attention Weights and Context Vectors**"
      ],
      "metadata": {
        "id": "O_wiZw9rs0IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = tf.nn.softmax(scaled, axis=-1)\n",
        "print(\"Attention Weights Matrix:\", weights)\n",
        "\n",
        "# Compute the context vectors as weighted sum of values\n",
        "context = tf.matmul(weights, values)\n",
        "print(\"Context vectors for each word:\")\n",
        "print(context.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_E_zrP2s7o2",
        "outputId": "66131518-ceb0-4562-c448-2a78048136e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Weights Matrix: tf.Tensor(\n",
            "[[8.8538527e-02 2.4323590e-01 6.6822553e-01]\n",
            " [7.7575515e-03 8.3941586e-02 9.0830088e-01]\n",
            " [5.3761917e-04 2.2913132e-02 9.7654927e-01]], shape=(3, 3), dtype=float32)\n",
            "Context vectors for each word:\n",
            "[[1.5109997 1.8637496]\n",
            " [1.7163478 2.1204348]\n",
            " [1.7646476 2.1808093]]\n"
          ]
        }
      ]
    }
  ]
}